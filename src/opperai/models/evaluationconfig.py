"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from enum import Enum
from opperai.types import BaseModel
import pydantic
from pydantic import ConfigDict
from typing import Any, Dict, List, Optional, Union
from typing_extensions import NotRequired, TypeAliasType, TypedDict


class ScorersEnum2(str, Enum):
    BASE = "base"
    RUBRICS = "rubrics"
    TOXICITY = "toxicity"
    HALLUCINATION = "hallucination"
    QA = "qa"
    AGENT_TOOL_SELECTION = "agent_tool_selection"
    REGEX = "regex"
    MAX_LENGTH = "max_length"


ScorersUnion1TypedDict = TypeAliasType(
    "ScorersUnion1TypedDict", Union[ScorersEnum2, Dict[str, Any]]
)


ScorersUnion1 = TypeAliasType("ScorersUnion1", Union[ScorersEnum2, Dict[str, Any]])


class ScorersEnum1(str, Enum):
    BASE = "base"
    RUBRICS = "rubrics"
    TOXICITY = "toxicity"
    HALLUCINATION = "hallucination"
    QA = "qa"
    AGENT_TOOL_SELECTION = "agent_tool_selection"
    REGEX = "regex"
    MAX_LENGTH = "max_length"


ScorersUnion2TypedDict = TypeAliasType(
    "ScorersUnion2TypedDict",
    Union[ScorersEnum1, Dict[str, Any], List[ScorersUnion1TypedDict]],
)
r"""Evaluation scorers to run: 'base', 'rubrics', 'toxicity', 'hallucination', 'qa', 'agent_tool_selection', 'regex', 'max_length', or a list of them."""


ScorersUnion2 = TypeAliasType(
    "ScorersUnion2", Union[ScorersEnum1, Dict[str, Any], List[ScorersUnion1]]
)
r"""Evaluation scorers to run: 'base', 'rubrics', 'toxicity', 'hallucination', 'qa', 'agent_tool_selection', 'regex', 'max_length', or a list of them."""


class EvaluationConfigTypedDict(TypedDict):
    r"""Configuration for evaluation features stored under 'beta.evaluation'.

    - enabled: master switch
    - scorers: which evaluators to run. Accepts:
    - string: \"base\" | \"rubrics\" | \"toxicity\" | \"hallucination\" | \"qa\"
    - dict: { \"rubrics\": RubricDefinition-like payload }
    - list[str | dict]
    \"base\" is the default scorer.
    """

    enabled: NotRequired[bool]
    r"""Enable evaluation features (base or rubrics)."""
    scorers: NotRequired[ScorersUnion2TypedDict]
    r"""Evaluation scorers to run: 'base', 'rubrics', 'toxicity', 'hallucination', 'qa', 'agent_tool_selection', 'regex', 'max_length', or a list of them."""


class EvaluationConfig(BaseModel):
    r"""Configuration for evaluation features stored under 'beta.evaluation'.

    - enabled: master switch
    - scorers: which evaluators to run. Accepts:
    - string: \"base\" | \"rubrics\" | \"toxicity\" | \"hallucination\" | \"qa\"
    - dict: { \"rubrics\": RubricDefinition-like payload }
    - list[str | dict]
    \"base\" is the default scorer.
    """

    model_config = ConfigDict(
        populate_by_name=True, arbitrary_types_allowed=True, extra="allow"
    )
    __pydantic_extra__: Dict[str, Any] = pydantic.Field(init=False)

    enabled: Optional[bool] = True
    r"""Enable evaluation features (base or rubrics)."""

    scorers: Optional[ScorersUnion2] = None
    r"""Evaluation scorers to run: 'base', 'rubrics', 'toxicity', 'hallucination', 'qa', 'agent_tool_selection', 'regex', 'max_length', or a list of them."""

    @property
    def additional_properties(self):
        return self.__pydantic_extra__

    @additional_properties.setter
    def additional_properties(self, value):
        self.__pydantic_extra__ = value  # pyright: ignore[reportIncompatibleVariableOverride]
